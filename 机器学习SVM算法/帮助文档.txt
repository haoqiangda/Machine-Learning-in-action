支持向量机算法常用的最流行的是SMO算法。
该算法的核心思想：
            每次循环的过程中选择两个alpha进行优化处理，一旦找到一对合适的alpha，那么就增大其中一个同时减少另一个。
     所谓的“合适”是指--1.这两个alpha必须在间隔边界之外。2.这两个alpha还没有进行过区间化处理，或者不在边界上。
通过SMO算法我们可以求出alpha(alpha>0，也是对应的支持向量)，和b




支持向量机的模型求解主要是求解w和b  而其中的w是通过这个alpha来求解
显示出支持向量机的一个重要的性质：
              训练完成之后，大部分的训练样本都不需要保留，最终模型只与支持向量有关。因为是从支持向量中构造出其w的解，
同时也暗示着复杂程度之与支持向量的数目有关。



以上两种分割的数据是testSet,，这个数据集中两个类的数据点分布在一条直线的两边。


如果数据为复杂数据---非线性可分的情况，那么分类应用核函数工具。将内积转换成核函数的方式
  
核方法就是将数据从一个低维空间映射到高维的空间。
                从而将低维空间的非线性问题转换为高维空间的线性问题来求解。

径向基核函数--在代码中主要通过两行代码来实现。
kernelEval = kernelTrans(sVs,datMat[i,:],kTup)  
------根据smo算法得到的支持向量的点svs进行核转换        
predict=kernelEval.T * multiply(labelSV,alphas[svInd]) + b 通过得到的数据与标签，支持向量对应的alpha相乘+b得到预测的类别类型


支持向量机----是一个二值决策过程。具有良好的学习能力，也就是有推广性能好的优点。