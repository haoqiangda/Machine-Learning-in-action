产生多个个体学习器的方案：AdaBoost、Bagging、随机森林


Bagging主要是降低分类器的方差，而Boosting主要关注降低分类器的偏差。

在AdaBoost算法中。第一个基分类器是个普通的分类器，基于所有的数据集产生。
                  然后根据产生的表现对训练样本分布进行调整（首先进行分类器权重更新，然后再更新样本--对于样本的更新，主要是改变每个样本所对应的权值）
                  -------关键一步--分类正确的样本的权值变低
                  基于新的样本分布，进行训练下一个基学习器。
                  重复T次。
注意：两次加权处理1.是关于训练样本的加权处理。2.是关于每个分类器最终得到结果根据其错误率赋予不同的权值，在进行加权处理。
标准的AdaBoost只是适用于二分类的任务，但是Bagging是一个很高效的集成学习算法。可适用于多分类、回归等任务

Bagging通常对多分类任务使用简单的投票法，对回归任务使用简单的平均法。

Bagging中的基学习器的多样性仅是通过样本扰动（通过对初始训练集随机采样）而来。
而“随机森林”中的基学习器的多样性不仅来自样本的扰动，还来自属性的扰动。

随机森林与Bagging最大的不同在于属性的扰动。
    
     Bagging使用的是“确定性”决策树，在选择划分属性时，要对结点的所有属性进行考察。
     随机森林使用的是“随机型”决策树，只需考察随机选取的一个属性子集。


    其随机森林针对决策树算法而言，对决策树中的每个结点，先从该结点的属性集合中随机选择一个包含k个属性的子集，
然后再从这个子集中选择一个最优属性用于划分。这里的参数K控制了随机性的引入程度。
        K=d,则该基决策树的构建与传统决策树相同。
        K=1,则是随机选择一个属性用于进行划分。  
性能比较：随机森林的收敛性与Bagging类似，但是随机森林的起始性能往往相对较差，随着个体学习器数目的增加，随机
森林通常会收敛到更低的泛化误差。


结合策略（将产生的多个个体学习器进行结合）：平均法、投票法、学习法



平均法：就是对各个个体学习器的输出进行操作。
        最具代表性的是加权平均。在个体学习器性能相差较大的时候应宜使用加权平均。
                                在其性能相近时，宜使用简单平均法。
        加权平均主要其权重的处理----------一般是通过估计个体学习器的误差，然后令权重的大小与误差大小成反比。

投票法：绝对多数投票法：若某标记得票数过半数，则预测为该标记，否则拒绝预测。
        相对多数投票法：预测为得票最多的标记，若同时多个标记获得最高票，从中随机选取一个。
        加权投票法：与加权平均法类似，主要求权重。
学习法：训练数据很多时。其是一个更为强大的结合策略。
         通过另一个学习器来进行结合---次级学习器。




在集成学习器中需要有效的生成多样性大的个体学习器。
如何增加多样性： 
                1.数据样本扰动---基于采样法
                  对其比较敏感的学习器：决策树、神经网络
                2.输入属性扰动---针对的是相对稳定的学习器
                  比如说：线性学习器、支持向量机、朴素贝叶斯、K近邻学习器。
                3.输出表示扰动----对训练样本的类标记稍作变动。
                4.算法参数扰动---比如说：神经网络的隐层神经元数、初始链接权值等参数的改变。


课后习题：
4.GradientBoosting是一种常用的Boosting算法，是分析其与AdaBoost的异同。
GradientBoosting与AdaBoost相同的地方在于要生成多个分类器以及每个分类器都有一个权值，最后将所有分类器加权累加起来
不同在于：
AdaBoost通过每个分类器的分类结果改变每个样本的权值用于新的分类器和生成权值，但不改变每个样本不会改变。
GradientBoosting将每个分类器对样本的预测值与真实值的差值传入下一个分类器来生成新的分类器和权值(这个差值就是下降方向)，而每个样本的权值不变

6.试述为什么Bagging难以提升朴素贝叶斯分类器的性能。
Bagging主要是降低分类器的方差，而朴素贝叶斯分类器没有方差可以减小。
对全训练样本生成的朴素贝叶斯分类器是最优的分类器，不能用随机抽样来提高泛化性能。